{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from src.dataloader.meta_loader import Dataloader4SER, NShotMAMLSampler, SERNShot\n",
    "from src.audio.audio import AudioProcessor\n",
    "\n",
    "from src.meta_learner.meta_learner import Meta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:True\n",
      " | > duration:None\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:80\n",
      " | > mel_fmax:7600\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      "There are 6 samples for training and 6 for out-of-distribution language.\n",
      "n_class train = 6 | n_class test = 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\src\\dataloader\\meta_loader.py:241: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  self.data = np.array(self.data)\n",
      "..\\src\\dataloader\\meta_loader.py:242: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  self.test_data = np.array(self.test_data)\n"
     ]
    }
   ],
   "source": [
    "# Testing loader\n",
    "N_WAY = 5\n",
    "K_SHOT = 2\n",
    "import torch.utils.data as data\n",
    "import torch\n",
    "\n",
    "ap = AudioProcessor(fft_size = 1024,\n",
    "                    hop_length = 256,\n",
    "                    win_length = 1024,\n",
    "                    pad_wav=False,\n",
    "                    num_mels = 80,\n",
    "                    mel_fmin = 80,\n",
    "                    mel_fmax = 7600,\n",
    "                    sample_rate = 22050,\n",
    "                    duration = None,\n",
    "                    resample = True,\n",
    "                    signal_norm= True,\n",
    "                    ref_level_db = 20,\n",
    "                    min_level_db = -100,\n",
    "                    symetric_norm = True,\n",
    "                    max_norm = 4)\n",
    "\n",
    "nshot = SERNShot(df_train_path = 'df.csv', df_test_path = 'df.csv', ap = ap, batch_size = 2, n_way = N_WAY, k_shot = K_SHOT, k_query = K_SHOT//2, pad_to = 200, pad_value = -3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ARGS:\n",
    "    \n",
    "    def __init__(self):\n",
    "    \n",
    "        self.update_lr = 0.01\n",
    "        self.meta_lr = 0.01\n",
    "        self.n_way = 7\n",
    "        self.k_spt = 2\n",
    "        self.k_qry = 1\n",
    "        self.task_num = 8\n",
    "        self.update_step = 5\n",
    "        self.update_step_test = 10\n",
    "        self.imgsz = 80\n",
    "        self.imgc = 1\n",
    "        self.epoch = 1\n",
    "    \n",
    "args = ARGS()\n",
    "\n",
    "config = [\n",
    "    ('conv2d', [32, 1, 3, 3, 1, 0]),\n",
    "    ('relu', [True]),\n",
    "    ('bn', [32]),\n",
    "    ('max_pool2d', [2, 2, 0]),\n",
    "    ('conv2d', [32, 32, 3, 3, 1, 0]),\n",
    "    ('relu', [True]),\n",
    "    ('bn', [32]),\n",
    "    ('max_pool2d', [2, 2, 0]),\n",
    "    ('conv2d', [32, 32, 3, 3, 1, 0]),\n",
    "    ('relu', [True]),\n",
    "    ('bn', [32]),\n",
    "    ('max_pool2d', [2, 2, 0]),\n",
    "    ('conv2d', [32, 32, 3, 3, 1, 0]),\n",
    "    ('relu', [True]),\n",
    "    ('bn', [32]),\n",
    "    ('max_pool2d', [2, 1, 0]),\n",
    "    ('flatten', []),\n",
    "    ('linear', [args.n_way, 3200])\n",
    "]\n",
    "\n",
    "\n",
    "maml = Meta(args, config).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta(\n",
      "  (net): Learner(\n",
      "    conv2d:(ch_in:1, ch_out:32, k:3x3, stride:1, padding:0)\n",
      "    relu:(True,)\n",
      "    bn:(32,)\n",
      "    max_pool2d:(k:2, stride:2, padding:0)\n",
      "    conv2d:(ch_in:32, ch_out:32, k:3x3, stride:1, padding:0)\n",
      "    relu:(True,)\n",
      "    bn:(32,)\n",
      "    max_pool2d:(k:2, stride:2, padding:0)\n",
      "    conv2d:(ch_in:32, ch_out:32, k:3x3, stride:1, padding:0)\n",
      "    relu:(True,)\n",
      "    bn:(32,)\n",
      "    max_pool2d:(k:2, stride:2, padding:0)\n",
      "    conv2d:(ch_in:32, ch_out:32, k:3x3, stride:1, padding:0)\n",
      "    relu:(True,)\n",
      "    bn:(32,)\n",
      "    max_pool2d:(k:2, stride:1, padding:0)\n",
      "    flatten:()\n",
      "    linear:(in:3200, out:7)\n",
      "    \n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.cuda.FloatTensor of size 32x1x3x3 (GPU 0)]\n",
      "        (1): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (2): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (3): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (4): Parameter containing: [torch.cuda.FloatTensor of size 32x32x3x3 (GPU 0)]\n",
      "        (5): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (6): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (7): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (8): Parameter containing: [torch.cuda.FloatTensor of size 32x32x3x3 (GPU 0)]\n",
      "        (9): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (10): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (11): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (12): Parameter containing: [torch.cuda.FloatTensor of size 32x32x3x3 (GPU 0)]\n",
      "        (13): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (14): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (15): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (16): Parameter containing: [torch.cuda.FloatTensor of size 7x3200 (GPU 0)]\n",
      "        (17): Parameter containing: [torch.cuda.FloatTensor of size 7 (GPU 0)]\n",
      "    )\n",
      "    (vars_bn): ParameterList(\n",
      "        (0): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (1): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (2): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (3): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (4): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (5): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (6): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (7): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 50727\n"
     ]
    }
   ],
   "source": [
    "tmp = filter(lambda x: x.requires_grad, maml.parameters())\n",
    "num = sum(map(lambda x: np.prod(x.shape), tmp))\n",
    "print(maml)\n",
    "print('Total trainable tensors:', num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in range(args.epoch):\n",
    "\n",
    "    x_spt, y_spt, x_qry, y_qry = nshot.next()\n",
    "    x_spt, y_spt, x_qry, y_qry = torch.from_numpy(x_spt).to(device), torch.from_numpy(y_spt).type(torch.LongTensor).to(device), \\\n",
    "                                 torch.from_numpy(x_qry).to(device), torch.from_numpy(y_qry).type(torch.LongTensor).to(device)\n",
    "\n",
    "    # set traning=True to update running_mean, running_variance, bn_weights, bn_bias\n",
    "    accs = maml(x_spt, y_spt, x_qry, y_qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 0, 0, 4, 3, 2, 1, 1, 3, 2],\n",
       "        [4, 1, 1, 0, 2, 0, 2, 3, 4, 3]], device='cuda:0')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_spt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3, 0.3, 0.3, 0.3, 0.3, 0.3])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n",
      "Test acc: [0.2 0.2 0.3 0.2 0.2 0.2 0.3 0.3 0.3 0.3 0.3]\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "for _ in range(10//args.task_num):\n",
    "    # test\n",
    "    x_spt, y_spt, x_qry, y_qry = nshot.next('test')\n",
    "    x_spt, y_spt, x_qry, y_qry = torch.from_numpy(x_spt).to(device), torch.from_numpy(y_spt).to(device).type(torch.LongTensor), \\\n",
    "                                 torch.from_numpy(x_qry).to(device), torch.from_numpy(y_qry).to(device).type(torch.LongTensor)\n",
    "\n",
    "    # split to single task each time\n",
    "    for x_spt_one, y_spt_one, x_qry_one, y_qry_one in zip(x_spt, y_spt, x_qry, y_qry):\n",
    "        test_acc = maml.finetunning(x_spt_one, y_spt_one, x_qry_one, y_qry_one)\n",
    "        accs.append( test_acc )\n",
    "\n",
    "    print(\"DONE!\")\n",
    "# [b, update_step+1]\n",
    "accs = np.array(accs).mean(axis=0).astype(np.float16)\n",
    "print('Test acc:', accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 200, 80])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_spt_one.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from    copy import deepcopy\n",
    "net = deepcopy(maml.net)\n",
    "\n",
    "from    torch.nn import functional as F\n",
    "\n",
    "# 1. run the i-th task and compute loss for k=0\n",
    "logits = net(x_spt_one)\n",
    "loss = F.cross_entropy(logits, y_spt_one)\n",
    "grad = torch.autograd.grad(loss, net.parameters())\n",
    "fast_weights = list(map(lambda p: p[1] - maml.update_lr * p[0], zip(grad, net.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_q = net(x_qry_one, fast_weights, bn_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 7]), torch.Size([5, 1, 200, 80]))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_q.shape, x_qry_one.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "correct = torch.eq(pred_q, y_qry_one).sum().item()  # convert to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10//args.task_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 200, 80])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_qry_one.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 200, 80])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_spt_one.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m_audio",
   "language": "python",
   "name": "m_audio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
